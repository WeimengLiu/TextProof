# OpenAI配置
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1

# DeepSeek配置
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# Ollama配置（本地部署）
OLLAMA_BASE_URL=http://localhost:11434

# 默认使用的模型提供商
DEFAULT_MODEL_PROVIDER=openai
DEFAULT_MODEL_NAME=gpt-4-turbo-preview

# 可用的模型列表（用逗号分隔）
# OpenAI模型
OPENAI_MODELS=gpt-4-turbo-preview,gpt-4,gpt-3.5-turbo,gpt-4o-mini
# DeepSeek模型
DEEPSEEK_MODELS=deepseek-chat,deepseek-coder
# Ollama模型
OLLAMA_MODELS=llama2,llama3,qwen,mistral

# 文本分段配置
CHUNK_SIZE=2000
CHUNK_OVERLAP=200

# Ollama专用分段配置（针对本地大模型，显存有限的情况）
# 32B模型+16GB显存建议：OLLAMA_CHUNK_SIZE=800-1000, OLLAMA_CHUNK_OVERLAP=100-150
OLLAMA_CHUNK_SIZE=800
OLLAMA_CHUNK_OVERLAP=100

# 大模型整段直发阈值（字符数）
# 对 OpenAI / DeepSeek 等云端模型，单段文本长度 <= 该值时直接整段发送，不再切 chunk
FAST_PROVIDER_MAX_CHARS=10000

# 重试配置
MAX_RETRIES=3
RETRY_DELAY=1.0

# Prompt配置
# 自定义Prompt文件路径（可选，如果不设置则使用默认Prompt）
# PROMPT_FILE=./prompts/custom_prompt.txt
