"""FastAPIä¸»åº”ç”¨"""
import sys
import os
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# æ·»åŠ backendç›®å½•åˆ°è·¯å¾„
backend_dir = os.path.dirname(os.path.abspath(__file__))
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)

from fastapi import FastAPI, HTTPException, UploadFile, File, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import datetime as dt
from fastapi.responses import StreamingResponse
import io
from services.correction_service import CorrectionService
from services.task_manager import task_manager
from utils.diff_utils import highlight_diff, has_meaningful_changes
import config
import asyncio

logger = logging.getLogger(__name__)

app = FastAPI(title="å°è¯´æ–‡æœ¬ç²¾æ ¡ç³»ç»Ÿ", version="1.0.0")

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# è¯·æ±‚/å“åº”æ¨¡å‹
class CorrectionRequest(BaseModel):
    text: str
    provider: Optional[str] = None
    model_name: Optional[str] = None
    chunk_size: Optional[int] = None
    chunk_overlap: Optional[int] = None


class DiffRequest(BaseModel):
    text: str
    corrected: Optional[str] = None
    provider: Optional[str] = None
    model_name: Optional[str] = None


class CorrectionResponse(BaseModel):
    original: str
    corrected: str
    chunks_processed: int
    total_chunks: int
    has_changes: bool
    failed_chunks: Optional[int] = 0
    has_failures: Optional[bool] = False
    failure_details: Optional[List[Dict[str, Any]]] = None


class DiffResponse(BaseModel):
    original_segments: list
    corrected_segments: list
    has_changes: bool

class ManualResultRequest(BaseModel):
    original: str
    corrected: str
    filename: Optional[str] = None
    provider: Optional[str] = None
    model_name: Optional[str] = None


class HealthResponse(BaseModel):
    status: str
    provider: str
    model_name: str
    available: bool


# å…¨å±€æœåŠ¡å®ä¾‹ï¼ˆå¯æ ¹æ®è¯·æ±‚å‚æ•°åŠ¨æ€åˆ›å»ºï¼‰
_services: Dict[str, CorrectionService] = {}


def get_service(
    provider: Optional[str] = None,
    model_name: Optional[str] = None
) -> CorrectionService:
    """è·å–æˆ–åˆ›å»ºæ ¡å¯¹æœåŠ¡å®ä¾‹"""
    key = f"{provider or 'default'}:{model_name or 'default'}"
    
    if key not in _services:
        _services[key] = CorrectionService(
            provider=provider,
            model_name=model_name
        )
    
    return _services[key]


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "name": "å°è¯´æ–‡æœ¬ç²¾æ ¡ç³»ç»Ÿ",
        "version": "1.0.0",
        "description": "ç”¨äºå¯¹ç½‘ç»œä¸‹è½½çš„å°è¯´è¿›è¡Œæœ€å°ä¾µå…¥å¼ç²¾æ ¡"
    }


@app.get("/health", response_model=HealthResponse)
async def health_check(
    provider: Optional[str] = None,
    model_name: Optional[str] = None
):
    """å¥åº·æ£€æŸ¥"""
    try:
        service = get_service(provider, model_name)
        available = await service.health_check()
        
        return HealthResponse(
            status="ok" if available else "unavailable",
            provider=provider or config.settings.default_model_provider,
            model_name=model_name or config.settings.default_model_name,
            available=available
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/correct", response_model=CorrectionResponse)
async def correct_text(request: CorrectionRequest):
    """
    æ ¡å¯¹æ–‡æœ¬
    
    è¯·æ±‚ä½“ï¼š
    - text: å¾…æ ¡å¯¹çš„æ–‡æœ¬
    - provider: æ¨¡å‹æä¾›å•†ï¼ˆå¯é€‰ï¼‰
    - model_name: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
    - chunk_size: åˆ†æ®µå¤§å°ï¼ˆå¯é€‰ï¼‰
    - chunk_overlap: åˆ†æ®µé‡å å¤§å°ï¼ˆå¯é€‰ï¼‰
    """
    logger.info("[API] /api/correct called")
    logger.info("[API] Provider: %s, Model: %s", request.provider, request.model_name)
    logger.info("[API] Text length: %d characters", len(request.text))
    logger.info("[API] Chunk size: %s, Overlap: %s", request.chunk_size, request.chunk_overlap)
    
    try:
        service = get_service(
            provider=request.provider,
            model_name=request.model_name
        )
        
        # å¦‚æœæŒ‡å®šäº†chunkå‚æ•°ï¼Œåˆ›å»ºä¸´æ—¶æœåŠ¡å®ä¾‹
        if request.chunk_size or request.chunk_overlap:
            service = CorrectionService(
                provider=request.provider,
                model_name=request.model_name,
                chunk_size=request.chunk_size,
                chunk_overlap=request.chunk_overlap
            )
        
        logger.info("[API] Starting text correction...")
        result = await service.correct_text(request.text)
        logger.info("[API] Text correction completed")
        logger.info("[API] Chunks processed: %d/%d", result.get('chunks_processed'), result.get('total_chunks'))
        logger.info("[API] Failed chunks: %d", result.get('failed_chunks', 0))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–ï¼ˆå¿½ç•¥çº¯æ ¼å¼å·®å¼‚ï¼‰
        has_changes = has_meaningful_changes(result["original"], result["corrected"])
        
        # è‡ªåŠ¨ä¿å­˜ç»“æœåˆ°æ¯”å¯¹ç»“æœåˆ—è¡¨ï¼ˆå³ä½¿å‰ç«¯è¶…æ—¶æ–­å¼€ï¼Œç»“æœä¹Ÿä¼šä¿å­˜ï¼‰
        result_id = None
        try:
            now = dt.datetime.now()
            filename = f"è¾“å…¥æ¡†æ ¡å¯¹ç»“æœ_{now.strftime('%Y%m%d_%H%M%S')}"
            result_id = task_manager.save_manual_result(
                filename=filename,
                original=result["original"],
                corrected=result["corrected"],
                has_changes=has_changes,
                provider=request.provider,
                model_name=request.model_name,
            )
            logger.info("[API] Result saved to database with result_id: %s", result_id)
        except Exception as e:
            # ä¿å­˜å¤±è´¥ä¸å½±å“è¿”å›ç»“æœï¼Œä»…è®°å½•æ—¥å¿—
            logger.warning("[API] Failed to save result to database: %s", str(e))
        
        return CorrectionResponse(
            original=result["original"],
            corrected=result["corrected"],
            chunks_processed=result["chunks_processed"],
            total_chunks=result["total_chunks"],
            has_changes=has_changes,
            failed_chunks=result.get("failed_chunks", 0),
            has_failures=result.get("has_failures", False),
            failure_details=result.get("failure_details")
        )
    except Exception as e:
        logger.error("[API] Correction failed: %s", str(e))
        logger.exception(e)
        raise HTTPException(status_code=500, detail=f"æ ¡å¯¹å¤±è´¥: {str(e)}")


async def process_task_async(task_id: str, text: str, provider: Optional[str], model_name: Optional[str], use_chapters: bool = False):
    """å¼‚æ­¥å¤„ç†ä»»åŠ¡"""
    try:
        service = get_service(provider, model_name)
        task = task_manager.get_task(task_id)
        
        if not task:
            return
        
        if use_chapters:
            # æŒ‰ç« èŠ‚å¤„ç†
            from utils.chapter_splitter import ChapterSplitter
            chapter_splitter = ChapterSplitter()
            chapters = chapter_splitter.split_by_chapters(text)
            
            # æ›´æ–°ä»»åŠ¡ä¿¡æ¯
            task_manager.tasks[task_id]["total_chapters"] = len(chapters)
            
            corrected_chapters = []
            total_chunks = 0
            processed_chunks = 0
            
            for chapter in chapters:
                chapter_index = chapter["chapter_index"]
                chapter_title = chapter["chapter_title"]
                chapter_content = chapter["chapter_content"]
                
                # æ›´æ–°ç« èŠ‚çŠ¶æ€ä¸ºå¤„ç†ä¸­
                task_manager.update_chapter_status(task_id, chapter_index, "processing", chapter_title)
                
                # å¤„ç†ç« èŠ‚
                def chapter_progress_callback(current: int, total: int):
                    task_manager.update_task_progress(
                        task_id,
                        processed_chunks + current,
                        total_chunks,
                        chapter_index,
                        chapter_title
                    )
                
                chapter_result = await service.correct_text(chapter_content, progress_callback=chapter_progress_callback)
                
                # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å¤±è´¥
                has_failures = chapter_result.get("has_failures", False)
                failed_chunks = chapter_result.get("failed_chunks", 0)
                
                # æ›´æ–°ç« èŠ‚çŠ¶æ€
                if has_failures and failed_chunks == chapter_result.get("total_chunks", 0):
                    # æ‰€æœ‰ç‰‡æ®µéƒ½å¤±è´¥
                    task_manager.update_chapter_status(task_id, chapter_index, "failed", chapter_title)
                else:
                    # å®Œæˆï¼ˆå¯èƒ½æœ‰éƒ¨åˆ†å¤±è´¥ï¼‰
                    task_manager.update_chapter_status(task_id, chapter_index, "completed", chapter_title)
                
                corrected_chapters.append({
                    "chapter_index": chapter_index,
                    "chapter_title": chapter_title,
                    "original": chapter_result["original"],
                    "corrected": chapter_result["corrected"],
                    "has_changes": has_meaningful_changes(chapter_result["original"], chapter_result["corrected"]),
                    "chunks_processed": chapter_result["chunks_processed"],
                    "total_chunks": chapter_result["total_chunks"],
                    "failed_chunks": failed_chunks,
                    "has_failures": has_failures,
                })
                
                processed_chunks += chapter_result["total_chunks"]
                total_chunks += chapter_result["total_chunks"]
            
            # åˆå¹¶æ‰€æœ‰ç« èŠ‚ï¼ˆåŒ…å«ç« èŠ‚æ ‡é¢˜ï¼‰
            original_text = "\n\n".join([
                f"{ch['chapter_title']}\n\n{ch['original']}" 
                for ch in corrected_chapters
            ])
            corrected_text = "\n\n".join([
                f"{ch['chapter_title']}\n\n{ch['corrected']}" 
                for ch in corrected_chapters
            ])
            has_changes = any(ch["has_changes"] for ch in corrected_chapters)
            
            task_manager.complete_task(task_id, original_text, corrected_text, has_changes, corrected_chapters)
        else:
            # æ™®é€šå¤„ç†
            def progress_callback(current: int, total: int):
                task_manager.update_task_progress(task_id, current, total)
            
            result = await service.correct_text(text, progress_callback=progress_callback)
            
            has_changes = has_meaningful_changes(result["original"], result["corrected"])
            task_manager.complete_task(task_id, result["original"], result["corrected"], has_changes)
    except Exception as e:
        task_manager.fail_task(task_id, str(e))


@app.post("/api/correct/file")
async def correct_file(
    file: UploadFile = File(...),
    provider: Optional[str] = Query(None),
    model_name: Optional[str] = Query(None),
    async_task: bool = Query(False)  # ä»æŸ¥è¯¢å‚æ•°è·å–
):
    """
    ä¸Šä¼ æ–‡ä»¶è¿›è¡Œæ ¡å¯¹
    
    æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼šTXT
    
    å‚æ•°:
    - async_task: æ˜¯å¦ä»¥åå°ä»»åŠ¡æ–¹å¼å¤„ç†ï¼ˆé»˜è®¤falseï¼ŒåŒæ­¥å¤„ç†ï¼‰
    """
    if not file.filename.endswith('.txt'):
        raise HTTPException(status_code=400, detail="ä»…æ”¯æŒTXTæ–‡ä»¶")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        text = content.decode('utf-8')
        file_size = len(content)
        
        # å¦‚æœå¯ç”¨åå°ä»»åŠ¡
        if async_task:
            # æ£€æµ‹æ˜¯å¦åº”è¯¥æŒ‰ç« èŠ‚å¤„ç†ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
            from utils.chapter_splitter import ChapterSplitter
            chapter_splitter = ChapterSplitter()
            chapter_info = chapter_splitter.detect_chapters(text)
            use_chapters = chapter_info["has_chapters"] and chapter_info["chapter_count"] > 1
            
            # åˆ›å»ºä»»åŠ¡
            task_id = task_manager.create_task(
                filename=file.filename,
                file_size=file_size,
                provider=provider,
                model_name=model_name,
                use_chapters=use_chapters
            )
            
            # å¯åŠ¨åå°ä»»åŠ¡
            asyncio.create_task(process_task_async(task_id, text, provider, model_name, use_chapters))
            
            response = {
                "task_id": task_id,
                "message": "ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨åå°å¤„ç†",
                "async": True
            }
            
            if use_chapters:
                response["use_chapters"] = True
                response["chapter_count"] = chapter_info["chapter_count"]
                response["message"] = f"ä»»åŠ¡å·²åˆ›å»ºï¼Œæ£€æµ‹åˆ°{chapter_info['chapter_count']}ä¸ªç« èŠ‚ï¼Œæ­£åœ¨æŒ‰ç« èŠ‚å¤„ç†"
            
            return response
        else:
            # åŒæ­¥å¤„ç†
            service = get_service(provider, model_name)
            result = await service.correct_text(text)
            
            has_changes = has_meaningful_changes(result["original"], result["corrected"])
            
            return CorrectionResponse(
                original=result["original"],
                corrected=result["corrected"],
                chunks_processed=result["chunks_processed"],
                total_chunks=result["total_chunks"],
                has_changes=has_changes
            )
    except UnicodeDecodeError:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œè¯·ä½¿ç”¨UTF-8ç¼–ç ")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ ¡å¯¹å¤±è´¥: {str(e)}")


@app.post("/api/diff", response_model=DiffResponse)
async def get_diff(request: DiffRequest):
    """
    è·å–æ–‡æœ¬å·®å¼‚å¯¹æ¯”
    
    è¯·æ±‚ä½“ï¼š
    - text: åŸæ–‡
    - corrected: æ ¡å¯¹åçš„æ–‡æœ¬ï¼ˆå¦‚æœæä¾›ï¼Œåˆ™ä½¿ç”¨ï¼›å¦åˆ™å…ˆæ ¡å¯¹å†å¯¹æ¯”ï¼‰
    - provider: æ¨¡å‹æä¾›å•†ï¼ˆå¯é€‰ï¼‰
    - model_name: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
    """
    try:
        # å¦‚æœæ²¡æœ‰æä¾›correctedï¼Œå…ˆè¿›è¡Œæ ¡å¯¹
        if not request.corrected:
            service = get_service(
                provider=request.provider,
                model_name=request.model_name
            )
            correction_result = await service.correct_text(request.text)
            corrected_text = correction_result["corrected"]
        else:
            corrected_text = request.corrected
        
        diff_result = highlight_diff(request.text, corrected_text)
        
        return DiffResponse(
            original_segments=diff_result["original_segments"],
            corrected_segments=diff_result["corrected_segments"],
            has_changes=diff_result["has_changes"]
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å·®å¼‚è®¡ç®—å¤±è´¥: {str(e)}")


@app.get("/api/providers")
async def get_providers():
    """è·å–å¯ç”¨çš„æ¨¡å‹æä¾›å•†åˆ—è¡¨"""
    from models.factory import ModelAdapterFactory
    return {
        "providers": ModelAdapterFactory.get_available_providers(),
        "default": config.settings.default_model_provider
    }


@app.get("/api/models")
async def get_models(provider: Optional[str] = None):
    """
    è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
    
    å‚æ•°:
    - provider: æ¨¡å‹æä¾›å•†ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸æä¾›åˆ™è¿”å›æ‰€æœ‰æä¾›å•†çš„æ¨¡å‹
    """
    if provider:
        models = config.settings.get_models_by_provider(provider)
        return {
            "provider": provider,
            "models": models,
            "default": config.settings.default_model_name if provider == config.settings.default_model_provider else None
        }
    else:
        all_models = config.settings.get_all_models()
        return {
            "models": all_models,
            "default_provider": config.settings.default_model_provider,
            "default_model": config.settings.default_model_name
        }


@app.get("/api/prompt")
async def get_prompt(reload: bool = Query(False)):
    """
    è·å–å½“å‰ä½¿ç”¨çš„Prompt
    
    å‚æ•°:
    - reload: æ˜¯å¦é‡æ–°ä»æ–‡ä»¶åŠ è½½ï¼ˆé»˜è®¤falseï¼Œä½¿ç”¨ç¼“å­˜ï¼‰
    """
    from utils.prompt_manager import prompt_manager
    return {
        "prompt": prompt_manager.get_prompt(reload=reload),
        "is_custom": config.settings.prompt_file is not None,
        "prompt_file": config.settings.prompt_file,
    }


@app.post("/api/prompt")
async def update_prompt(request: Dict[str, Any]):
    """
    æ›´æ–°Prompt
    
    è¯·æ±‚ä½“:
    - prompt: æ–°çš„Promptæ–‡æœ¬
    - persist: æ˜¯å¦æŒä¹…åŒ–ä¿å­˜ï¼ˆé»˜è®¤falseï¼‰
    """
    from utils.prompt_manager import prompt_manager
    import os
    
    if "prompt" not in request:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘promptå­—æ®µ")
    
    prompt_text = request["prompt"]
    persist = request.get("persist", False)
    
    # æ›´æ–°Prompt
    prompt_manager.set_prompt(prompt_text)
    
    message = "Promptå·²æ›´æ–°å¹¶ç«‹å³ç”Ÿæ•ˆ"
    prompt_file_path = None
    
    if persist:
        try:
            # ä¿å­˜åˆ°é»˜è®¤æ–‡ä»¶
            saved_path = prompt_manager.save_prompt_to_default_file()
            prompt_file_path = saved_path
            
            # æ›´æ–°.envæ–‡ä»¶ä¸­çš„PROMPT_FILEé…ç½®
            backend_dir = os.path.dirname(os.path.abspath(__file__))
            env_path = os.path.join(backend_dir, ".env")
            
            if os.path.exists(env_path):
                # è¯»å–ç°æœ‰.envæ–‡ä»¶
                with open(env_path, "r", encoding="utf-8") as f:
                    env_lines = f.readlines()
                
                # æ›´æ–°æˆ–æ·»åŠ PROMPT_FILEé…ç½®
                new_lines = []
                prompt_file_updated = False
                relative_path = "./prompts/custom_prompt.txt"
                
                for line in env_lines:
                    stripped = line.strip()
                    if stripped.startswith("PROMPT_FILE="):
                        new_lines.append(f"PROMPT_FILE={relative_path}\n")
                        prompt_file_updated = True
                    else:
                        new_lines.append(line)
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°PROMPT_FILEï¼Œæ·»åŠ åˆ°Prompté…ç½®åŒºåŸŸ
                if not prompt_file_updated:
                    # æŸ¥æ‰¾Prompté…ç½®åŒºåŸŸæˆ–æ–‡ä»¶æœ«å°¾
                    added = False
                    for i, line in enumerate(new_lines):
                        if "# Prompté…ç½®" in line or "# Prompt" in line:
                            # åœ¨Prompté…ç½®åŒºåŸŸæ·»åŠ 
                            j = i + 1
                            while j < len(new_lines) and new_lines[j].strip().startswith("#"):
                                j += 1
                            new_lines.insert(j, f"PROMPT_FILE={relative_path}\n")
                            added = True
                            break
                    
                    if not added:
                        # æ·»åŠ åˆ°æ–‡ä»¶æœ«å°¾
                        new_lines.append(f"\n# Prompté…ç½®\nPROMPT_FILE={relative_path}\n")
                
                # å†™å…¥æ–‡ä»¶
                with open(env_path, "w", encoding="utf-8") as f:
                    f.writelines(new_lines)
            
            message = f"Promptå·²æ›´æ–°å¹¶ç«‹å³ç”Ÿæ•ˆï¼Œå·²ä¿å­˜åˆ°æ–‡ä»¶å¹¶æ›´æ–°.envé…ç½®ï¼ˆé‡å¯åä¹Ÿä¼šç”Ÿæ•ˆï¼‰"
        except Exception as e:
            message = f"Promptå·²æ›´æ–°å¹¶ç«‹å³ç”Ÿæ•ˆï¼Œä½†ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}"
    else:
        message = "Promptå·²æ›´æ–°å¹¶ç«‹å³ç”Ÿæ•ˆï¼ˆé‡å¯åæ¢å¤ä¸ºé…ç½®æ–‡ä»¶ä¸­çš„Promptï¼‰"
    
    return {
        "message": message,
        "prompt": prompt_manager.get_prompt(),
        "persisted": persist,
        "prompt_file": prompt_file_path,
    }


@app.get("/api/config")
async def get_config():
    """è·å–ç³»ç»Ÿé…ç½®ä¿¡æ¯"""
    return {
        "chunk_size": config.settings.chunk_size,
        "chunk_overlap": config.settings.chunk_overlap,
        "ollama_chunk_size": config.settings.ollama_chunk_size,
        "ollama_chunk_overlap": config.settings.ollama_chunk_overlap,
        "fast_provider_max_chars": getattr(config.settings, "fast_provider_max_chars", 10000),
        "max_retries": config.settings.max_retries,
        "retry_delay": config.settings.retry_delay,
        "default_provider": config.settings.default_model_provider,
        "default_model": config.settings.default_model_name,
        "openai_models": config.settings.openai_models,
        "deepseek_models": config.settings.deepseek_models,
        "ollama_models": config.settings.ollama_models,
    }


@app.post("/api/config")
async def update_config(request: Dict[str, Any]):
    """
    æ›´æ–°ç³»ç»Ÿé…ç½®
    
    è¯·æ±‚ä½“:
    - chunk_size: æ–‡æœ¬åˆ†æ®µå¤§å°ï¼ˆå¯é€‰ï¼‰
    - chunk_overlap: åˆ†æ®µé‡å å¤§å°ï¼ˆå¯é€‰ï¼‰
    - ollama_chunk_size: Ollamaä¸“ç”¨åˆ†æ®µå¤§å°ï¼ˆå¯é€‰ï¼Œé’ˆå¯¹æœ¬åœ°å¤§æ¨¡å‹ï¼‰
    - ollama_chunk_overlap: Ollamaä¸“ç”¨åˆ†æ®µé‡å å¤§å°ï¼ˆå¯é€‰ï¼‰
    - fast_provider_max_chars: äº‘ç«¯å¤§æ¨¡å‹æ•´æ®µç›´å‘é˜ˆå€¼ï¼ˆå­—ç¬¦æ•°ï¼Œå¯é€‰ï¼‰
    - max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆå¯é€‰ï¼‰
    - retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆå¯é€‰ï¼‰
    - default_provider: é»˜è®¤æ¨¡å‹æä¾›å•†ï¼ˆå¯é€‰ï¼‰
    - default_model: é»˜è®¤æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
    - openai_models: OpenAIæ¨¡å‹åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    - deepseek_models: DeepSeekæ¨¡å‹åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    - ollama_models: Ollamaæ¨¡å‹åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    - persist: æ˜¯å¦æŒä¹…åŒ–åˆ°.envæ–‡ä»¶ï¼ˆé»˜è®¤falseï¼Œä»…è¿è¡Œæ—¶æ›´æ–°ï¼‰
    """
    update_data = {}
    
    # éªŒè¯å¹¶å‡†å¤‡æ›´æ–°æ•°æ®
    if "chunk_size" in request:
        chunk_size = int(request["chunk_size"])
        if chunk_size <= 0:
            raise HTTPException(status_code=400, detail="chunk_sizeå¿…é¡»å¤§äº0")
        update_data["chunk_size"] = chunk_size
    
    if "chunk_overlap" in request:
        chunk_overlap = int(request["chunk_overlap"])
        if chunk_overlap < 0:
            raise HTTPException(status_code=400, detail="chunk_overlapä¸èƒ½å°äº0")
        update_data["chunk_overlap"] = chunk_overlap
    
    if "ollama_chunk_size" in request:
        ollama_chunk_size = int(request["ollama_chunk_size"])
        if ollama_chunk_size <= 0:
            raise HTTPException(status_code=400, detail="ollama_chunk_sizeå¿…é¡»å¤§äº0")
        update_data["ollama_chunk_size"] = ollama_chunk_size
    
    if "ollama_chunk_overlap" in request:
        ollama_chunk_overlap = int(request["ollama_chunk_overlap"])
        if ollama_chunk_overlap < 0:
            raise HTTPException(status_code=400, detail="ollama_chunk_overlapä¸èƒ½å°äº0")
        update_data["ollama_chunk_overlap"] = ollama_chunk_overlap
    
    if "fast_provider_max_chars" in request:
        fast_provider_max_chars = int(request["fast_provider_max_chars"])
        if fast_provider_max_chars <= 0:
            raise HTTPException(status_code=400, detail="fast_provider_max_charså¿…é¡»å¤§äº0")
        update_data["fast_provider_max_chars"] = fast_provider_max_chars
    
    if "max_retries" in request:
        max_retries = int(request["max_retries"])
        if max_retries < 0:
            raise HTTPException(status_code=400, detail="max_retriesä¸èƒ½å°äº0")
        update_data["max_retries"] = max_retries
    
    if "retry_delay" in request:
        retry_delay = float(request["retry_delay"])
        if retry_delay < 0:
            raise HTTPException(status_code=400, detail="retry_delayä¸èƒ½å°äº0")
        update_data["retry_delay"] = retry_delay
    
    if "default_provider" in request:
        update_data["default_model_provider"] = request["default_provider"]
    
    if "default_model" in request:
        update_data["default_model_name"] = request["default_model"]
    
    if "openai_models" in request:
        update_data["openai_models"] = request["openai_models"]
    
    if "deepseek_models" in request:
        update_data["deepseek_models"] = request["deepseek_models"]
    
    if "ollama_models" in request:
        update_data["ollama_models"] = request["ollama_models"]
    
    if not update_data:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰æä¾›è¦æ›´æ–°çš„é…ç½®é¡¹")
    
    # æ›´æ–°é…ç½®
    persist = request.get("persist", False)
    
    try:
        # å…ˆæ›´æ–°è¿è¡Œæ—¶é…ç½®
        config.settings.update_runtime_config(**update_data)

        # é…ç½®æ›´æ–°åï¼Œæ¸…ç©ºå·²ç¼“å­˜çš„æœåŠ¡å®ä¾‹ï¼Œç¡®ä¿ä¸‹æ¬¡è°ƒç”¨ä½¿ç”¨æœ€æ–°é…ç½®
        # å°¤å…¶æ˜¯ä¾èµ– chunk_size / ollama_chunk_size ç­‰åœ¨ __init__ ä¸­åˆå§‹åŒ–çš„å¯¹è±¡
        global _services
        _services.clear()
        
        if persist:
            # æŒä¹…åŒ–åˆ°.envæ–‡ä»¶
            success = config.settings.save_to_env_file()
            if success:
                message = "é…ç½®å·²æ›´æ–°å¹¶ç«‹å³ç”Ÿæ•ˆï¼ŒåŒæ—¶å·²ä¿å­˜åˆ°.envæ–‡ä»¶ï¼ˆé‡å¯åä¹Ÿä¼šç”Ÿæ•ˆï¼‰"
            else:
                message = "é…ç½®å·²æ›´æ–°å¹¶ç«‹å³ç”Ÿæ•ˆï¼Œä½†ä¿å­˜åˆ°.envæ–‡ä»¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™"
        else:
            # ä»…è¿è¡Œæ—¶æ›´æ–°
            message = "é…ç½®å·²æ›´æ–°å¹¶ç«‹å³ç”Ÿæ•ˆï¼ˆé‡å¯åæ¢å¤ä¸º.envæ–‡ä»¶ä¸­çš„å€¼ï¼‰"
        
        return {
            "message": message,
            "persisted": persist,
            "config": {
                "chunk_size": config.settings.chunk_size,
                "chunk_overlap": config.settings.chunk_overlap,
                "ollama_chunk_size": config.settings.ollama_chunk_size,
                "ollama_chunk_overlap": config.settings.ollama_chunk_overlap,
                "fast_provider_max_chars": getattr(config.settings, "fast_provider_max_chars", 10000),
                "max_retries": config.settings.max_retries,
                "retry_delay": config.settings.retry_delay,
                "default_provider": config.settings.default_model_provider,
                "default_model": config.settings.default_model_name,
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ›´æ–°é…ç½®å¤±è´¥: {str(e)}")


@app.get("/api/tasks")
async def get_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨"""
    tasks = task_manager.get_all_tasks()
    return {"tasks": tasks}


@app.get("/api/tasks/{task_id}")
async def get_task(task_id: str):
    """è·å–ä»»åŠ¡è¯¦æƒ…"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return task


@app.get("/api/results")
async def get_results():
    """è·å–æ‰€æœ‰æ¯”å¯¹ç»“æœåˆ—è¡¨"""
    # Pagination (production)
    # Keep response shape compatible: still returns {"results": [...]}
    # Extra: {"total","limit","offset"}
    try:
        # default: first page
        page = task_manager.store.list_results(limit=50, offset=0)
        return {"results": page.items, "total": page.total, "limit": page.limit, "offset": page.offset}
    except Exception:
        # fallback (should not happen)
        results = task_manager.get_all_results()
        return {"results": results}


@app.get("/api/results/{result_id}")
async def get_result(result_id: str, include_text: bool = Query(True)):
    """è·å–æ¯”å¯¹ç»“æœè¯¦æƒ…"""
    # Production default: include_text=True for backward compatibility with current frontend.
    # For very large results, client can set include_text=false then use download endpoint.
    result = task_manager.store.get_result(result_id=result_id, include_text=include_text, include_chapter_meta=True)
    if not result:
        raise HTTPException(status_code=404, detail="ç»“æœä¸å­˜åœ¨")
    
    # å¦‚æœç»“æœå¾ˆå¤§ï¼Œç®€åŒ–è¿”å›ï¼ˆå‰ç«¯å¯ä»¥å•ç‹¬è¯·æ±‚ç« èŠ‚ï¼‰
    if result.get("use_chapters") and result.get("chapters"):
        chapters = result["chapters"]
        # ç« èŠ‚å…ƒæ•°æ®æ¥è‡ª storeï¼Œåªæœ‰ original_length/corrected_lengthï¼Œæ—  original/corrected æ–‡æœ¬
        total_original = sum(ch.get("original_length", 0) for ch in chapters)
        total_corrected = sum(ch.get("corrected_length", 0) for ch in chapters)
        simplified_result = {
            "result_id": result["result_id"],
            "task_id": result.get("task_id"),
            "filename": result["filename"],
            "has_changes": result["has_changes"],
            "use_chapters": True,
            "chapter_count": len(chapters),
            "original_length": total_original,
            "corrected_length": total_corrected,
            "provider": result.get("provider"),
            "model_name": result.get("model_name"),
            "chapters": [
                {
                    "chapter_index": ch["chapter_index"],
                    "chapter_title": ch["chapter_title"],
                    "has_changes": ch.get("has_changes", False),
                    "original_length": ch.get("original_length", 0),
                    "corrected_length": ch.get("corrected_length", 0),
                }
                for ch in chapters
            ],
            "created_at": result["created_at"],
            "completed_at": result.get("completed_at"),
        }
        return simplified_result
    
    return result


@app.get("/api/results/{result_id}/chapters/{chapter_index}")
async def get_chapter_result(result_id: str, chapter_index: int):
    """è·å–æŒ‡å®šç« èŠ‚çš„æ¯”å¯¹ç»“æœ"""
    meta = task_manager.store.get_result(result_id=result_id, include_text=False, include_chapter_meta=False)
    if not meta:
        raise HTTPException(status_code=404, detail="ç»“æœä¸å­˜åœ¨")
    if not meta.get("use_chapters"):
        raise HTTPException(status_code=400, detail="è¯¥ç»“æœä¸æ˜¯æŒ‰ç« èŠ‚å¤„ç†çš„")
    chapter = task_manager.store.get_chapter(result_id=result_id, chapter_index=chapter_index)
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    return chapter


@app.delete("/api/results/{result_id}")
async def delete_result(result_id: str):
    """åˆ é™¤æ¯”å¯¹ç»“æœ"""
    success = task_manager.store.delete_result(result_id=result_id)
    if not success:
        raise HTTPException(status_code=404, detail="ç»“æœä¸å­˜åœ¨")
    return {"message": "ç»“æœå·²åˆ é™¤", "result_id": result_id}


@app.post("/api/results/manual")
async def save_manual_result(request: ManualResultRequest):
    """ä¿å­˜â€œè¾“å…¥æ¡†ç›´æ¥æ ¡å¯¹â€çš„æ¯”å¯¹ç»“æœåˆ°ç»“æœåˆ—è¡¨"""
    if not request.original or not request.corrected:
        raise HTTPException(status_code=400, detail="original å’Œ corrected ä¸èƒ½ä¸ºç©º")

    filename = request.filename or f"è¾“å…¥æ¡†æ ¡å¯¹ç»“æœ_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}"
    has_changes = has_meaningful_changes(request.original, request.corrected)

    result_id = task_manager.save_manual_result(
        filename=filename,
        original=request.original,
        corrected=request.corrected,
        has_changes=has_changes,
        provider=request.provider,
        model_name=request.model_name,
    )
    return {"message": "ç»“æœå·²ä¿å­˜", "result_id": result_id}


@app.get("/api/results/{result_id}/download")
async def download_result(
    result_id: str,
    which: str = Query("corrected"),
    chapter_index: Optional[int] = Query(None),
):
    """
    ä¸‹è½½ç»“æœæ–‡æœ¬ï¼ˆæµå¼è¾“å‡ºï¼Œç”Ÿäº§å‹å¥½ï¼‰
    - which: original | corrected
    - chapter_index: ç« èŠ‚ç´¢å¼•ï¼ˆä»…ç« èŠ‚ç»“æœï¼‰
    """
    if which not in ("original", "corrected"):
        raise HTTPException(status_code=400, detail="which å¿…é¡»æ˜¯ original æˆ– corrected")

    meta = task_manager.store.get_result(result_id=result_id, include_text=False, include_chapter_meta=False)
    if not meta:
        raise HTTPException(status_code=404, detail="ç»“æœä¸å­˜åœ¨")

    filename_base = meta.get("filename") or result_id

    if meta.get("use_chapters"):
        if chapter_index is None:
            raise HTTPException(status_code=400, detail="è¯¥ç»“æœæŒ‰ç« èŠ‚å¤„ç†ï¼Œè¯·æä¾› chapter_index")
        chapter = task_manager.store.get_chapter(result_id=result_id, chapter_index=int(chapter_index))
        if not chapter:
            raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
        text = chapter.get(which) or ""
        chapter_title = chapter.get("chapter_title") or f"chapter_{chapter_index}"
        download_name = f"{filename_base}_{chapter_title}_{which}.txt"
    else:
        full = task_manager.store.get_result(result_id=result_id, include_text=True, include_chapter_meta=False)
        text = (full or {}).get(which) or ""
        download_name = f"{filename_base}_{which}.txt"

    data = text.encode("utf-8")
    return StreamingResponse(
        io.BytesIO(data),
        media_type="text/plain; charset=utf-8",
        headers={"Content-Disposition": f'attachment; filename=\"{download_name}\"'},
    )


if __name__ == "__main__":
    import uvicorn
    import argparse
    
    parser = argparse.ArgumentParser(description="å¯åŠ¨æ–‡æœ¬ç²¾æ ¡ç³»ç»Ÿåç«¯æœåŠ¡")
    parser.add_argument(
        "--dev",
        action="store_true",
        help="å¼€å‘æ¨¡å¼ï¼šå¯ç”¨çƒ­é‡è½½ï¼ˆä»£ç ä¿®æ”¹åè‡ªåŠ¨é‡å¯ï¼‰"
    )
    parser.add_argument(
        "--host",
        type=str,
        default="0.0.0.0",
        help="ç›‘å¬åœ°å€ï¼ˆé»˜è®¤: 0.0.0.0ï¼‰"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8000,
        help="ç›‘å¬ç«¯å£ï¼ˆé»˜è®¤: 8000ï¼‰"
    )
    parser.add_argument(
        "--reload-dir",
        type=str,
        default=None,
        help="ç›‘å¬é‡è½½çš„ç›®å½•ï¼ˆé»˜è®¤: å½“å‰ç›®å½•ï¼‰"
    )
    
    args = parser.parse_args()
    
    reload_dirs = [os.path.dirname(os.path.abspath(__file__))]
    if args.reload_dir:
        reload_dirs.append(args.reload_dir)
    
    if args.dev:
        logger.info("=" * 60)
        logger.info("ğŸš€ å¯åŠ¨å¼€å‘æ¨¡å¼ï¼ˆçƒ­é‡è½½å·²å¯ç”¨ï¼‰")
        logger.info("ğŸ“ åœ°å€: http://%s:%d", args.host, args.port)
        logger.info("ğŸ“ ç›‘å¬ç›®å½•: %s", ', '.join(reload_dirs))
        logger.info("ğŸ’¡ ä»£ç ä¿®æ”¹åä¼šè‡ªåŠ¨é‡å¯æœåŠ¡")
        logger.info("=" * 60)
        uvicorn.run(
            "main:app",
            host=args.host,
            port=args.port,
            reload=args.dev,
            reload_dirs=reload_dirs if args.dev else None,
            log_level="info"
        )
    else:
        logger.info("=" * 60)
        logger.info("ğŸš€ å¯åŠ¨ç”Ÿäº§æ¨¡å¼")
        logger.info("ğŸ“ åœ°å€: http://%s:%d", args.host, args.port)
        logger.info("ğŸ’¡ ä½¿ç”¨ --dev å‚æ•°å¯ç”¨å¼€å‘æ¨¡å¼ï¼ˆçƒ­é‡è½½ï¼‰")
        logger.info("=" * 60)
        uvicorn.run(
            app,
            host=args.host,
            port=args.port,
            log_level="info"
        )
